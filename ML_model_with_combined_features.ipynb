   "source": [
    "## import sklearn\n",
    "from sklearn import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import * \n",
    "#%matplotlib inline \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import *\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.tree import *\n",
    "import forestci as fci\n",
    "\n",
    "#loading features from csv-files\n",
    "features = pd.read_csv('Data_set_Hsp90_combined_features.csv', ';', usecols=['6.8','16.7','7.8','8.8','16.8','mass eigen value high','mass eigen value low','gasteiger charge eigenvalue high','gasteiger charge low','crippen lowgp eigenvalue high','crippen lowgp low','crippen mr eigenvalue high','crippen mr low','logkoff','MWT','valence electrons','TPSA','rotatable bonds','logP','molar refractivity','non-cyclic nitrogen','acyclic single valent nodes', 'cyclic trivalent nodes','acyclic trivalent nodes','6.6', '7.6','8.6'])\n",
    "features.head(72)\n",
    "features = pd.get_dummies(features, prefix_sep='_', dtype=float)#for the smiles code -> (0/1)\n",
    "features.iloc[:,:].head(72)\n",
    "labels = np.array(features['logkoff'])#labels value we want to predict\n",
    "features= features.drop('logkoff', axis = 1)#remove the label, axis=1 is the column\n",
    "feature_list = list(features.columns) #saving for later\n",
    "features = np.array(features)\n",
    "\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.2, random_state = 7)\n",
    "\n",
    "\n",
    "#Building the RondomForestGegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators = 270,max_depth = 26,max_features = 'log2', random_state = 7)\n",
    "rf.fit(train_features, train_labels)\n",
    "predictions = rf.predict(test_features)\n",
    "errors = abs(predictions - test_labels)\n",
    "\n",
    "#Calculate different metrics for comparing thr ML-model\n",
    "print('Mean absolute Error in koff:',round(np.mean(errors), 5), 'per second.')\n",
    "predicted = rf.predict(train_features)\n",
    "expected = train_labels\n",
    "\n",
    "numerator = ((test_labels - predictions) ** 2).sum()\n",
    "denominator = ((test_labels - np.average(test_labels)) ** 2).sum()\n",
    "r2_score1 = 1 - (numerator / denominator)\n",
    "print('R2-score test-set:',round(r2_score1,3))\n",
    "\n",
    "numerator = ((expected - predicted) ** 2).sum()\n",
    "denominator = ((expected - np.average(expected)) ** 2).sum()\n",
    "r2_score2 = 1 - (numerator / denominator)\n",
    "print('R2-score train-set:',round(r2_score2,3))\n",
    "\n",
    "\n",
    "import math\n",
    " \n",
    "MSE = np.square(np.subtract(test_labels,predictions)).mean() \n",
    " \n",
    "RMSE = math.sqrt(MSE)\n",
    "print(\"RMSE test-set:\", round(RMSE,3))\n",
    "\n",
    "MSEt = np.square(np.subtract(expected,predicted)).mean() \n",
    " \n",
    "RMSEt = math.sqrt(MSEt)\n",
    "print(\"RMSE train-set:\", round(RMSEt,3))\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "MAE = mean_absolute_error(test_labels, predictions)\n",
    "print('MAE test-set:',round(MAE,3))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "MAE = mean_absolute_error(expected, predicted)\n",
    "print('MAE train-set:',round(MAE,3))\n",
    "\n",
    "#plot the predicted and expected datapoints with errorbars\n",
    "plt.style.use('ggplot')\n",
    "predictions_data = pd.DataFrame(data = {'koff': test_labels, 'prediction': predictions})\n",
    "x = test_labels\n",
    "y = predictions_data['prediction']\n",
    "mpg_V_IJ_unbiased = fci.random_forest_error(rf, train_features, test_features)\n",
    "plt.errorbar(x, y, yerr=np.sqrt(mpg_V_IJ_unbiased), fmt = '.r')\n",
    "plt.plot([-4.5, 0.0], [-4.5, 0.0], linestyle = '--', color = 'grey')\n",
    "plt.plot(x,y,'s',markersize = 7.5, label='test-set, $R^2$=0.849', color = 'red')\n",
    "plt.plot(expected, predicted, '^',markersize = 7.5, label='train-set, $R^2$=0.944', color ='green')\n",
    "plt.xlim(0,-4.5)\n",
    "plt.ylim(0,-4.5)\n",
    "plt.xlabel('experimental log koff (log s-1)', fontsize=12)\n",
    "plt.ylabel('predicted log koff (log s-1)', fontsize=12)\n",
    "plt.legend(loc='upper left', fontsize=12)\n",
    "plt.title('Experimental and Predicted Values', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "#calculating the feature importance with permutation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "r = permutation_importance(rf, test_features, test_labels, n_repeats=30, random_state=0)\n",
    "for i in r.importances_mean.argsort()[::-1]:\n",
    "#    if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "         print('Measured with permutation:',\n",
    "               (f\"{feature_list[i]:24}\"\n",
    "               f\"{r.importances_mean[i]:.3f}\"\n",
    "               f\" +/- {r.importances_std[i]:.3f}\"),)\n",
    "\n",
    "#sort the features wth the standard deviations after the importance    \n",
    "a = (list(feature_list))\n",
    "b = list(r.importances_mean)\n",
    "c = list(r.importances_std)\n",
    "my_dict={}\n",
    "for i in range(len(a)):\n",
    "    my_dict[a[i]]= (b[i],c[i])\n",
    "\n",
    "sorted_dictonary=sorted(my_dict.items(), key=lambda x: x[1])\n",
    "sorted_keys=[k for k, v in sorted_dictonary]\n",
    "sorted_errors=[v[1] for k, v in sorted_dictonary]\n",
    "sorted_importance=[v[0] for k, v in sorted_dictonary]\n",
    "\n",
    "#plot the calculated importance\n",
    "plt.style.use('ggplot')\n",
    "x_values = list(range(len(a)))\n",
    "plt.bar(sorted_keys, sorted_importance, orientation = 'vertical', color = 'darkblue', facecolor=None, yerr=sorted_errors)\n",
    "plt.xticks(x_values, rotation='vertical', fontsize=11)\n",
    "plt.yticks(fontsize=11)\n",
    "plt.ylabel('Importance'); plt.xlabel('Feature'); plt.title('Feature importances measured with permutation')\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f343d70b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
